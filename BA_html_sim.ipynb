{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D48mKghyv9ZW"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.4' requires the ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: '/usr/local/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gejz0PfgwGAu"
      },
      "outputs": [],
      "source": [
        "# function for reading from file\n",
        "def read_file(filename):\n",
        "    text=[]\n",
        "    with open(filename, 'r') as f:\n",
        "        text.append (f.read())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "j9kFpBszxGou"
      },
      "outputs": [],
      "source": [
        "# function to toknize sentences\n",
        "def tokenize_sentences(text):\n",
        "    return sent_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZGxTbPIPwTMZ"
      },
      "outputs": [],
      "source": [
        "#function for vectorizing text\n",
        "def vectorize_text(sentences):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
        "    return tfidf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "h_zbN4tXxdln"
      },
      "outputs": [],
      "source": [
        "#function to compute cos-sim\n",
        "def compute_cos_sim(sentences):\n",
        "    tfidf_matrix = vectorize_text(sentences)\n",
        "    cos_sim_matrix = cosine_similarity(tfidf_matrix)\n",
        "    return cos_sim_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ijp073Tbx2lL"
      },
      "outputs": [],
      "source": [
        "#function to create color for each similar text\n",
        "def similarity_to_color(similarity, min_val=0.0, max_val=1.0):\n",
        "    normalized = (similarity - min_val) / (max_val - min_val)\n",
        "    r = int(normalized * 255)\n",
        "    g = 0\n",
        "    b = int((1 - normalized) * 255)\n",
        "    # Convert RGB to hex color code\n",
        "    return '#%02x%02x%02x' % (r, g, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u0O0-t8H09f_"
      },
      "outputs": [],
      "source": [
        "#generate the html tag to put in the file\n",
        "def generate_html(sentences, similarity_matrix):\n",
        "    max_similarity = np.max(similarity_matrix)\n",
        "    min_similarity = np.min(similarity_matrix)\n",
        "\n",
        "    html_sentences = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        avg_similarity = np.mean(similarity_matrix[i])\n",
        "        color = similarity_to_color(avg_similarity, max_similarity, min_similarity)\n",
        "        html_sentence = f'<span style=\"background-color: {color}\">{sentence}</span>'\n",
        "        html_sentences.append(html_sentence)\n",
        "\n",
        "    return ' '.join(html_sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ut1JoCZ11RQG"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "   file_path=input()\n",
        "   texts=read_file(file_path)\n",
        "   for text in texts:\n",
        "      sentences = tokenize_sentences(text)\n",
        "\n",
        "   similarity_matrix=compute_cos_sim(sentences)\n",
        "   html_content=generate_html(sentences, similarity_matrix)\n",
        "   with open('highlighted_sentences.html', 'w') as file:\n",
        "        file.write('<html><body>')\n",
        "        file.write(html_content)\n",
        "        file.write('</body></html>')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
